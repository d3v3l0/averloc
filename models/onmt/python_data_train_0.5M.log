[2019-10-24 23:26:24,157 INFO]  * src vocab size = 50002
[2019-10-24 23:26:24,157 INFO]  * tgt vocab size = 31223
[2019-10-24 23:26:24,158 INFO] Building model...
[2019-10-24 23:26:27,753 INFO] NMTModel(
  (encoder): RNNEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(50002, 500, padding_idx=1)
        )
      )
    )
    (rnn): LSTM(500, 250, num_layers=2, dropout=0.3, bidirectional=True)
  )
  (decoder): InputFeedRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(31223, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout(p=0.3, inplace=False)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.3, inplace=False)
      (layers): ModuleList(
        (0): LSTMCell(1000, 500)
        (1): LSTMCell(500, 500)
      )
    )
    (attn): GlobalAttention(
      (linear_in): Linear(in_features=500, out_features=500, bias=False)
      (linear_out): Linear(in_features=1000, out_features=500, bias=False)
    )
  )
  (generator): Sequential(
    (0): Linear(in_features=500, out_features=31223, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2019-10-24 23:26:27,754 INFO] encoder: 28009000
[2019-10-24 23:26:27,754 INFO] decoder: 37012223
[2019-10-24 23:26:27,754 INFO] * number of parameters: 65021223
[2019-10-24 23:26:27,756 INFO] Starting training on GPU: [0]
[2019-10-24 23:26:27,756 INFO] Start training loop and validate every 10000 steps...
[2019-10-24 23:26:27,756 INFO] Loading dataset from python_data_500000.train.0.pt
[2019-10-24 23:26:32,444 INFO] number of examples: 343595
[2019-10-24 23:26:39,889 INFO] Step 50/100000; acc:  20.42; ppl: 467858.99; xent: 13.06; lr: 1.00000; 10993/907 tok/s;     12 sec
[2019-10-24 23:26:46,052 INFO] Step 100/100000; acc:  22.62; ppl: 185084.55; xent: 12.13; lr: 1.00000; 25808/1896 tok/s;     18 sec
[2019-10-24 23:26:51,774 INFO] Step 150/100000; acc:  21.49; ppl: 16107.10; xent: 9.69; lr: 1.00000; 23571/2064 tok/s;     24 sec
[2019-10-24 23:26:57,955 INFO] Step 200/100000; acc:  28.05; ppl: 1468.48; xent: 7.29; lr: 1.00000; 27523/1848 tok/s;     30 sec
[2019-10-24 23:27:03,785 INFO] Step 250/100000; acc:  28.34; ppl: 1419.88; xent: 7.26; lr: 1.00000; 25688/2011 tok/s;     36 sec
[2019-10-24 23:27:09,349 INFO] Step 300/100000; acc:  28.06; ppl: 966.92; xent: 6.87; lr: 1.00000; 24413/2117 tok/s;     42 sec
[2019-10-24 23:27:15,303 INFO] Step 350/100000; acc:  30.67; ppl: 916.06; xent: 6.82; lr: 1.00000; 25677/1927 tok/s;     48 sec
[2019-10-24 23:27:20,730 INFO] Step 400/100000; acc:  34.43; ppl: 456.75; xent: 6.12; lr: 1.00000; 25926/1882 tok/s;     53 sec
[2019-10-24 23:27:26,387 INFO] Step 450/100000; acc:  29.16; ppl: 742.17; xent: 6.61; lr: 1.00000; 24088/2106 tok/s;     59 sec
[2019-10-24 23:27:57,102 INFO]  * src vocab size = 50002
[2019-10-24 23:27:57,102 INFO]  * tgt vocab size = 31223
[2019-10-24 23:27:57,102 INFO] Building model...
[2019-10-24 23:28:00,690 INFO] NMTModel(
  (encoder): RNNEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(50002, 500, padding_idx=1)
        )
      )
    )
    (rnn): LSTM(500, 250, num_layers=2, dropout=0.3, bidirectional=True)
  )
  (decoder): InputFeedRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(31223, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout(p=0.3, inplace=False)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.3, inplace=False)
      (layers): ModuleList(
        (0): LSTMCell(1000, 500)
        (1): LSTMCell(500, 500)
      )
    )
    (attn): GlobalAttention(
      (linear_in): Linear(in_features=500, out_features=500, bias=False)
      (linear_out): Linear(in_features=1000, out_features=500, bias=False)
    )
  )
  (generator): Sequential(
    (0): Linear(in_features=500, out_features=31223, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2019-10-24 23:28:00,691 INFO] encoder: 28009000
[2019-10-24 23:28:00,691 INFO] decoder: 37012223
[2019-10-24 23:28:00,691 INFO] * number of parameters: 65021223
[2019-10-24 23:28:00,692 INFO] Starting training on GPU: [0]
[2019-10-24 23:28:00,692 INFO] Start training loop and validate every 5000 steps...
[2019-10-24 23:28:00,693 INFO] Loading dataset from python_data_500000.train.0.pt
[2019-10-24 23:28:05,401 INFO] number of examples: 343595
[2019-10-24 23:28:13,677 INFO] Step 50/50000; acc:  17.49; ppl: 335583.78; xent: 12.72; lr: 1.00000; 12729/910 tok/s;     13 sec
[2019-10-24 23:28:19,538 INFO] Step 100/50000; acc:  14.91; ppl: 15109279.58; xent: 16.53; lr: 1.00000; 23950/1956 tok/s;     19 sec
[2019-10-24 23:28:25,301 INFO] Step 150/50000; acc:  24.11; ppl: 30494.69; xent: 10.33; lr: 1.00000; 23967/2070 tok/s;     25 sec
[2019-10-24 23:28:32,022 INFO] Step 200/50000; acc:  27.16; ppl: 2824.61; xent: 7.95; lr: 1.00000; 27060/1866 tok/s;     31 sec
[2019-10-24 23:28:37,898 INFO] Step 250/50000; acc:  30.12; ppl: 1320.56; xent: 7.19; lr: 1.00000; 26089/1945 tok/s;     37 sec
[2019-10-24 23:28:43,859 INFO] Step 300/50000; acc:  28.78; ppl: 934.13; xent: 6.84; lr: 1.00000; 25549/1909 tok/s;     43 sec
[2019-10-24 23:28:49,851 INFO] Step 350/50000; acc:  28.84; ppl: 870.17; xent: 6.77; lr: 1.00000; 26161/1986 tok/s;     49 sec
[2019-10-24 23:28:55,758 INFO] Step 400/50000; acc:  25.05; ppl: 1018.70; xent: 6.93; lr: 1.00000; 24607/2109 tok/s;     55 sec
[2019-10-24 23:29:01,616 INFO] Step 450/50000; acc:  28.93; ppl: 697.83; xent: 6.55; lr: 1.00000; 24883/1953 tok/s;     61 sec
[2019-10-24 23:29:07,207 INFO] Step 500/50000; acc:  30.29; ppl: 582.79; xent: 6.37; lr: 1.00000; 24821/1921 tok/s;     67 sec
[2019-10-24 23:29:13,436 INFO] Step 550/50000; acc:  27.66; ppl: 721.89; xent: 6.58; lr: 1.00000; 25322/2033 tok/s;     73 sec
[2019-10-24 23:29:19,369 INFO] Step 600/50000; acc:  32.19; ppl: 477.91; xent: 6.17; lr: 1.00000; 26406/1947 tok/s;     79 sec
[2019-10-24 23:29:24,930 INFO] Step 650/50000; acc:  29.17; ppl: 544.66; xent: 6.30; lr: 1.00000; 24022/2148 tok/s;     84 sec
[2019-10-24 23:29:30,910 INFO] Step 700/50000; acc:  32.53; ppl: 418.45; xent: 6.04; lr: 1.00000; 26565/1830 tok/s;     90 sec
